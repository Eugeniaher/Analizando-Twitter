knitr::opts_chunk$set(include = FALSE)
# Cargamos las librerías
library(readxl)
library(tidyverse)
library(lubridate)
library(stringdist)
library(data.table)
#Unimos los datasets en un uno nuevo (df_sputnik_union)
#df_sputnik_union <- rbind(sputnikV_RT, sputnikV_RT2,  sputnikV_RT3, sputnikV_RT4, sputnikV_RT5, sputnikV_RT6, sputnikV_RT7, sputnikV_RT8, sputnikV_RT9, sputnikV_RT10, sputnikV_RT11, sputnikV_RT12, sputnikV_RT13)
#Eliminamos los duplicados segun el status id
#df_sputnik_union <- df_sputnik_union[!duplicated(df_sputnik_union$status_id),]
#write.csv2(df_sputnik_union, "../Data/df_sputnik.csv", row.names = FALSE)
#df_sputnik_union <- df_sputnik_union %>% filter(location %like% "Argentina" | location %like% "Bolivia" |location %like% "Chile" | location %like% "Paraguay" |  location %like% "Uruguay") #Filtramos por los países limitrofes a Argentina
#Unimos los datasets en uno solo (df_pfizer_union)
# df_pfizer_union <- rbind(pfizer_RT, pfizer_RT2, pfizer_RT3, pfizer_RT4, pfizer_RT5, pfizer_RT6, pfizer_RT7, pfizer_RT8, pfizer_RT9, pfizer_RT10, pfizer_RT11, pfizer_RT12, pfizer_RT13)
#Eliminamos los duplicados segun el status id
# df_pfizer_union <- df_pfizer_union[!duplicated(df_pfizer_union$status_id),]
#df_pfizer_union <- df_pfizer_union %>% filter(location %like% "Argentina" | location %like% "Bolivia" |location %like% "Chile" | location %like% "Paraguay" |  location %like% "Uruguay") #Filtramos por los países limitrofes a Argentina
#Cargamos los df
df_pfizer <- read.csv2("../Data/df_pfizer.csv")
df_sputnik <- read.csv2("../Data/df_sputnik.csv")
#Creamos una función que nos permite seleccionar las columnas que son de nuestro interes. Además, cambiamos el formato de la variable fecha y la ordenamos de manera ascedente.
filtrar_df <- function(df) {
#Nos quedamos con las columnas que son de nuestro interes
df <- df %>% subset(, c(2, 3, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 31, 32, 49, 55, 56, 57, 75, 79, 85))
#Pasamos la variable created at de formato texto a formato fecha
df <- df %>% mutate(created_at = ymd_hms(created_at))
#Ordenamos los tweets por fecha de creacion
df <- df %>% arrange (created_at)
return(df)
}
#Creamos una función que nos limpie el texto para realizar text mining
limpiar_texto <- function(texto){
#Se convierte todo el texto a minúsculas
nuevo_texto <- tolower(texto)
#Eliminamos los corchetes angulares
nuevo_texto <- str_replace_all(nuevo_texto, "<([^<>]+)>", " ")
# Eliminamos páginas web (palabras que empiezan por "http." seguidas de cualquier cosa que no sea un espacio)
nuevo_texto <- str_replace_all(nuevo_texto,"http\\S*", "")
#Eliminamos los arroba
nuevo_texto <- str_replace_all (nuevo_texto, "@\\S*", "")
# Eliminamos los números
nuevo_texto <- str_replace_all(nuevo_texto,"[[:digit:]]", " ")
# Eliminamos los signos de puntuación
nuevo_texto <- str_replace_all(nuevo_texto,"[[:punct:]]", " ")
# Eliminamos espacios en blanco múltiples
nuevo_texto <- str_replace_all(nuevo_texto,"[\\s]+", " ")
# Eliminamos el signo medio -
nuevo_texto <- str_replace_all(nuevo_texto, "[-]", "")
return(nuevo_texto)
}
#Aplicamos la función filtrar_df
df_pfizer <- filtrar_df(df = df_pfizer)
#Aplicamos la función limpiar_texto, tanto en la variable texto como en la de ubicación.
df_pfizer$text <- limpiar_texto(texto = df_pfizer$text)
df_pfizer$location <- limpiar_texto(texto = df_pfizer$location)
#Aplicamos la función filtrar_df
df_sputnik <- filtrar_df(df = df_sputnik)
df_sputnik$text <- limpiar_texto(texto = df_sputnik$text)
df_sputnik$location <- limpiar_texto(texto = df_sputnik$location)
#Guardamos un df con rt, como nuestro df original, "df_pfizer", ya tiene los rt, lo unico que hacemos es guardarlo en csv con otro nombre "df_pfizer_RT_final"
write.csv2(df_pfizer, "df_pfizer_RT_final.csv", row.names = FALSE)
#Guardamos un df con rt, como nuestro df original, "df_sputnik", ya tiene los rt, lo unico que hacemos es guardarlo en csv con otro nombre "df_sputnik_RT_final"
write.csv2(df_sputnik, "df_sputnik_RT_final.csv", row.names = FALSE)
View(df_pfizer)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(data.table)
library(ggplot2)
library(plotly)
library(tidytext)
library(tm)
library(wordcloud2)
library(RColorBrewer)
library(topicmodels)
library(knitr)
df_pfizer_RT <- read.csv2("../Data/df_pfizer_RT_final.csv")
df_sputnik_RT <- read.csv2("../Data/df_sputnik_RT_final.csv")
fn_agrupar <- function(df) {
df <- df %>% mutate(created_at = ymd_hms(created_at))
df <- df %>% mutate(created_at = floor_date(created_at, unit = "day"))
#Agrupamos los tweets por tipo de vacuna
df <- df %>% group_by(vacuna)
#Contamos los tweets por día y tipo
df <- df %>% count(created_at)
return(df)
}
fn_tokenizar <- function(tk) {
tk <- tk %>% unnest_tokens(word,text)
return(tk)
}
fn_frecuencia <- function(frec) {
frec <- frec %>% count(word, sort = TRUE)
print(frec)
}
vacuna <- sample("pfizer", replace = TRUE)
df_pfizer_RT <- cbind(df_pfizer_RT, vacuna)
vacuna <- sample("sputnikv", replace = TRUE)
df_sputnik_RT <- cbind(df_sputnik_RT, vacuna)
View(df_sputnik_RT)
df_rt <- rbind(df_pfizer_RT, df_sputnik_RT)
pais <- sample("ARG", replace = TRUE)
df_argentina_rt <- df_rt %>%
filter(location %like% "argentina")
View(df_argentina_rt)
df_argentina_rt <- cbind(df_argentina_rt, pais)
pais <- sample("CL", replace = TRUE)
df_chile_rt <- df_rt %>%
filter(location %like% "chile")
df_chile_rt <- cbind(df_chile_rt, pais)
View(df_chile_rt)
pais <- sample("BO", replace = TRUE)
df_bolivia_rt <- df_rt %>%
filter(location %like% "bolivia")
df_bolivia_rt <- cbind(df_bolivia_rt, pais)
View(df_bolivia_rt)
pais <- sample("PY", replace = TRUE)
df_paraguay_rt <- df_rt %>%
filter(location %like% "paraguay")
df_paraguay_rt <- cbind(df_paraguay_rt, pais)
View(df_paraguay_rt)
pais <- sample("UY", replace = TRUE)
df_uruguay_rt <- df_rt %>%
filter(location %like% "uruguay")
df_uruguay_rt <- cbind(df_uruguay_rt, pais)
View(df_uruguay_rt)
contar_arg <- fn_agrupar(df = df_argentina_rt)
contar_chl <- fn_agrupar(df = df_chile_rt)
contar_py <- fn_agrupar(df = df_paraguay_rt)
contar_uy <- fn_agrupar(df = df_uruguay_rt)
contar_bo <- fn_agrupar(df = df_bolivia_rt)
contar_bo <- fn_agrupar(df = df_bolivia_rt)
View(contar_bo)
View(contar_chl)
p_diario_arg <- ggplot(contar_arg) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
theme_minimal()
ggplotly(p_diario_arg)
p_diario_ch <- ggplot(contar_chl) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x = "Fecha",
y = "n tweets",
title = "Cantidad de tweets por día y vacuna - Chile") +
theme_minimal()
ggplotly(p_diario_ch)
p_diario_bo <- ggplot(contar_bo) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Bolivia") +
theme_minimal()
ggplotly(p_diario_bo)
p_diario_uy <- ggplot(contar_uy) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Uruguay") +
theme_minimal()
ggplotly(p_diario_uy)
p_diario_py <- ggplot(contar_py) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Paraguay") +
theme_minimal()
ggplotly(p_diario_py)
df_rt <- rbind(df_argentina_rt, df_bolivia_rt, df_chile_rt, df_paraguay_rt, df_uruguay_rt)
contar_tot <- df_rt %>%
mutate(created_at = ymd_hms(created_at)) %>%
mutate(created_at = floor_date(created_at, unit = "day")) %>%
group_by(vacuna, pais) %>%
count(created_at)
View(contar_tot)
p_tot <- ggplot(contar_tot) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna") +
geom_col(show.legend = FALSE) +
facet_wrap(~pais, ncol = 2, nrow = 3, scales = "free") +
theme_minimal()
ggplotly(p_tot)
p_tot <- ggplot(contar_tot) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(title = "Cantidad de tweets por día y vacuna") +
#geom_col(show.legend = FALSE) +
facet_wrap(~pais, ncol = 2, nrow = 3, scales = "free") +
theme_minimal()
ggplotly(p_tot)
p_tot <- ggplot(contar_tot) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x=fecha, y = n, title = "Cantidad de tweets por día y vacuna") +
#geom_col(show.legend = FALSE) +
facet_wrap(~pais, ncol = 2, nrow = 3, scales = "free") +
theme_minimal()
ggplotly(p_tot)
p_tot <- ggplot(contar_tot) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
labs(x="fecha", y = "n", title = "Cantidad de tweets por día y vacuna") +
#geom_col(show.legend = FALSE) +
facet_wrap(~pais, ncol = 2, nrow = 3, scales = "free") +
theme_minimal()
ggplotly(p_tot)
fecha_dosis_sputnik <- ymd("2020-12-24")
fecha_vacunacion_sputnik <- ymd("2020-12-29")
p_hitos_arg <- ggplot(contar_arg) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
geom_text(aes( x=created_at, y=n, label=n), size=3, fontface="italic") +
scale_x_datetime(date_labels = "%d-%m", date_breaks = "3 day") +
labs(x = "Fecha", y = "Número de tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
geom_vline(aes(xintercept = as.POSIXct(fecha_dosis_sputnik)),
color = "orange", alpha = .7)  +
annotate("text", x = as.POSIXct(fecha_dosis_sputnik), y = 0,
label = "Arribo dosis SV", size = 3) +
geom_vline(aes(xintercept = as.POSIXct(fecha_vacunacion_sputnik)),
color = "orange", alpha = .7)  +
annotate("text", x = as.POSIXct(fecha_vacunacion_sputnik), y = 0,
label = "Inicio vacunación SV", size = 3) +
theme_minimal()
library(gganimate)
p_hitos_arg <- ggplot(contar_arg) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
geom_text(aes( x=created_at, y=n, label=n), size=3, fontface="italic") +
scale_x_datetime(date_labels = "%d-%m", date_breaks = "3 day") +
labs(x = "Fecha", y = "Número de tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
geom_vline(aes(xintercept = as.POSIXct(fecha_dosis_sputnik)),
color = "orange", alpha = .7)  +
annotate("text", x = as.POSIXct(fecha_dosis_sputnik), y = 0,
label = "Arribo dosis SV", size = 3) +
geom_vline(aes(xintercept = as.POSIXct(fecha_vacunacion_sputnik)),
color = "orange", alpha = .7)  +
annotate("text", x = as.POSIXct(fecha_vacunacion_sputnik), y = 0,
label = "Inicio vacunación SV", size = 3) +
theme_minimal()
annotate("text", x = "fecha_dosis_sputnik", y = 0,
label = "Arribo dosis SV", size = 3)
annotate("text", x = "fecha_dosis_sputnik", y = 0)
fecha_dosis_sputnik <- ymd("2020-12-24")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(data.table)
library(ggplot2)
library(plotly)
library(gganimate)
library(tidytext)
library(wordcloud)
library(RColorBrewer)
library(topicmodels)
#Cargo los df
df_pfizer_noRT <- read.csv2("../Data/df_pfizer_noRT_final.csv")
p_hitos_arg <- ggplot(contar_arg) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
geom_text(aes( x=created_at, y=n, label=n), size=3, fontface="italic") +
scale_x_datetime(date_labels = "%d-%m", date_breaks = "3 day") +
labs(x = "Fecha", y = "Número de tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
geom_vline(aes(xintercept = as.POSIXct(fecha_dosis_sputnik)),
color = "orange", alpha = .7)  +
annotate("text", x = as.POSIXct(fecha_dosis_sputnik), y = 0,
label = "Arribo dosis SV", size = 3)
library(ggrepel)
annotate("text", x = as.POSIXct(fecha_dosis_sputnik), y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = as.POSIXct(fecha_dosis_sputnik), y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = 2020-12-24, y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = "2020-12-24", y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = "24-12", y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = "24-dic", y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = 3, y = 0,
label = "Arribo dosis SV", size = 3)
annotate(geom = "text", x = 3, y = 0,
label="Arribo dosis SV", size=3)
annotate(geom = "text", x =3, y=0,
label="Arribo dosis SV", size=3)
p_hitos_arg <- ggplot(contar_arg) +
geom_line(aes(x = created_at, y = n, color = vacuna)) +
geom_text(aes( x=created_at, y=n, label=n), size=3, fontface="italic") +
scale_x_datetime(date_labels = "%d-%m", date_breaks = "3 day") +
labs(x = "Fecha", y = "Número de tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
geom_vline(aes(xintercept = as.POSIXct(fecha_dosis_sputnik)),
color = "orange", alpha = .7)  +
geom_vline(aes(xintercept = as.POSIXct(fecha_vacunacion_sputnik)),
color = "orange", alpha = .7)  +
theme_minimal()
p_hitos_arg
ggsave("p_hitos_arg.png")
p_hitos_arg
df_organicos_arg <- df_argentina_rt %>%
subset(is.na(reply_to_status_id)) %>%
filter(is_retweet == FALSE)
df_rtweets_arg <- df_argentina_rt %>%
filter(is_retweet==TRUE)
df_respuestas_arg <- df_argentina_rt %>% subset(!is.na(reply_to_status_id))
categorias_arg <- data.frame(category = c ("Organico", "Retweets", "Respuestas"),
count=c(7215, 37506, 2834))
categorias_arg$fraction = categorias_arg$count / sum(categorias_arg$count)
categorias_arg$percentage = categorias_arg$count / sum(categorias_arg$count) * 100
#Redondeamos el porcentaje de la columna 4 (percentage)
categorias_arg[,4] <-round(categorias_arg[,4],0)
ggplot(categorias_arg) +
geom_bar(mapping = aes(x= category, y = percentage, fill = category), stat = "identity") +
scale_fill_brewer(palette = "Accent") +
labs(x = "Categoria", y = "Porcentaje", title = "Porcentaje de tweets por categoría") +
geom_text(aes(x=category, y=percentage, label=percentage), size=3)
df_nort <- df_rt %>%
filter(is_retweet == FALSE)
#Creamos un df con datos de argentina que nos sirva para realizar luego el analisis de stop words. Pfizer
df_arg_noRT_pfizer <- df_nort %>%
filter(location %like% "argentina" & vacuna == "pfizer")
#Filtramos
count_arg_pfizer <- df_arg_noRT_pfizer %>%
select(screen_name, text, retweet_count, favorite_count, followers_count, verified) %>%
filter(retweet_count >= 100 | favorite_count >= 300) %>%
arrange(desc(retweet_count))
view(count_arg_pfizer)
df_arg_noRT_sputnik <- df_nort %>%
filter(location %like% "argentina" & vacuna == "sputnikv")
#Filtramos
count_arg_sputnik <- df_arg_noRT_sputnik %>%
select(screen_name, text, retweet_count, favorite_count, followers_count, verified) %>%
filter(retweet_count >= 100 | favorite_count >= 300) %>%
arrange(desc(retweet_count))
view(count_arg_sputnik)
token_pfizer_arg <- fn_tokenizar(tk = df_arg_noRT_pfizer)
token_sputnik_arg <- fn_tokenizar(tk = df_arg_noRT_sputnik)
custom_stop_words <- bind_rows(stop_words,
data_frame(word = tm::stopwords("spanish"), lexicon = "custom"))
palabras_sinaporte <- tibble(word = c("vacunas", "si", "informa", "a", "aa", "acá"))
token_sputnik_arg <- token_sputnik_arg %>%
anti_join(custom_stop_words) %>%
anti_join(palabras_sinaporte)
token_pfizer_arg <- token_pfizer_arg %>%
anti_join(custom_stop_words) %>%
anti_join(palabras_sinaporte)
fn_frecuencia(frec = token_pfizer_arg)
fn_frecuencia(frec = token_sputnik_arg)
token_pfizer_arg %>%
count(word, sort = TRUE) %>%
filter(n > 200 & n < 2000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = word)) +
geom_col() +
labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre Pfizer", subtitle = "Argentina") +
xlab(NULL) +
scale_fill_brewer(palette = "Spectral") +
geom_text(aes( x=word, y=n, label=n), size=3) +
coord_flip()
token_pfizer_arg %>%
count(word, sort = TRUE) %>%
filter(n > 200 & n < 2000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = word)) +
geom_col() +
labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre Pfizer", subtitle = "Argentina") +
xlab(NULL) +
scale_fill_brewer(palette = "Spectral") +
geom_text(aes( x=word, y=n, label=n), size=3) +
coord_flip()
wordcloud_pf <- token_pfizer_arg %>%
count(word, sort=T) %>%
filter(n < 2000) %>% #eliminamos la palabra pfizer de la nube
wordcloud2(size = 1, color = 'random-light', backgroundColor = "black")
wordcloud_pf
# Ploteamos las palabras más frecuentes
token_sputnik_arg %>%
count(word, sort = TRUE) %>%
filter(n > 600 & n < 6000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = word)) +
geom_col() +
labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre SputnikV", subtitle = "Argentina") +
xlab(NULL) +
scale_fill_brewer(palette = "Spectral") +
geom_text(aes( x=word, y=n, label=n), size=3) +
coord_flip()
wordcloud_sp <- token_sputnik_arg %>%
count(word, sort=T) %>%
filter(n < 3000) %>% #eliminamos la palabra sputnik de la nube
wordcloud2(size = 0.9, color = 'random-light', backgroundColor = "black")
wordcloud_sp
token_sputnik_arg%>%
count(word, sort=T) %>%
filter(n < 3000) %>%
with(wordcloud(word, n, color = brewer.pal(8, "Dark2")))
token_sputnik_arg %>%
count(word, sort=T) %>%
filter(n < 3000) %>% #eliminamos la palabra sputnik de la nube
wordcloud2(size = 0.9, color = 'random-light', backgroundColor = "black")
wordcloud_sp <- token_sputnik_arg %>%
count(word, sort=T) %>%
filter(n < 3000) %>% #eliminamos la palabra sputnik de la nube
wordcloud2(size = 0.9, color = 'random-light', backgroundColor = "black")
saveWidget(wordcloud_sp, '2.html', selfcontained = F)
library(webshot)
install.packages("webshot")
#install.packages("webshot")
library(webshot)
install.packages("htmlwidgets")
install.packages("htmlwidgets")
install.packages("htmlwidgets")
install.packages("htmlwidgets")
install.packages("htmlwidgets")
install.packages("htmlwidgets")
knitr::opts_chunk$set(echo = TRUE)
library(htmlwidgets)
install.packages("htmlwidgets")
library(htmlwidgets)
install.packages("htmlwidgets")
install.packages("htmlwidgets")
library(htmlwidgets)
library(htmlwidgets)
library(htmlwidgets)
