---
title: "Analizando twitter: menciones de las vacunas Pfizer y SputnikV"
author: "Eugenia Hernandez + Santiago Caviglia + Fernando Zaffaroni + Ornella Giansetto + Walter Baez"
date: "1/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(lubridate)
library(data.table)
library(ggplot2)
library(plotly)
library(tidytext)
library(tm)
library(wordcloud2)
library(RColorBrewer)
library(topicmodels)
library(knitr)
```

En el siguiente trabajo analizaremos las menciones que reciben las vacunas SputnikV y Pfizer en twitter. Para ello, descargamos cada dos días 18.000 mil tweets, por vacuna. Luego filtramos por los países que son de nuestro interes para analizar: los limítrofes a Argentina, dejando de lado a Brasil ya que su idioma es el portugues.

A través de dichos tweets, buscabamos analizar varias cosas: 

1. Por un lado, cuantificar las menciones por día que se realizaban de cada vacuna y para cada país limítrofe a Argentina. A su vez, al gráfico de Argentina le agregamos hitos que nos daban una respuesta a los picos de menciones.

2. Por otro lado, quisimos analizar cuál era la dinámica en twitter para tratar de entender cómo se forman/llevan adelante las conversaciones. 

    2.1 Dado que la mayoría de los tweets que circulan son retweets, quisimos tratar de entender quienes eran los formadores de opinión (siempre dentro de nuestro dataset)

3. Asimismo, analizamos cuáles son las palabras que se utilizan con más frecuencia cuando se menciona a una u otra vacuna. 

4. Analizamos también cuáles eran los sentimientos que se desprenden de dichos tweets.


```{r include=FALSE}
#Cargo los df

#Usamos "../" como una via alternativa para leer el csv desde cualquier equipo, sin importar en que carpeta descargue cada uno el proyecto. 

df_pfizer_RT <- read.csv2("../Data/df_pfizer_RT_final.csv")
df_sputnik_RT <- read.csv2("../Data/df_sputnik_RT_final.csv")

```


```{r include=FALSE}
#Creamos nuestras funciones 

#Creamos una función para agrupar los df por tipo de vacuna y contar el n por fecha

fn_agrupar <- function(df) {
  df <- df %>% mutate(created_at = ymd_hms(created_at)) 
  df <- df %>% mutate(created_at = floor_date(created_at, unit = "day"))
  #Agrupamos los tweets por tipo de vacuna
  df <- df %>% group_by(vacuna) 
  #Contamos los tweets por día y tipo
  df <- df %>% count(created_at) 
  return(df)
}

#Creamos una función para tokenizar nuestros datasets. 

fn_tokenizar <- function(tk) {
  tk <- tk %>% unnest_tokens(word,text)
  return(tk)
}

#Creamos una función para contar la frecuencia de palabras

fn_frecuencia <- function(frec) {
  frec <- frec %>% count(word, sort = TRUE)
  print(frec)
}

```


```{r include=FALSE}
#Preparamos el dataset para hacer comparaciones entre cantidad de menciones por vacuna. Para ello vamos a utilizar los df CON Retweet.

#Creo una columna nueva llamada "tipo" en los df con RT donde se va a aclarar si habla sobre la vacuna sputnikv o pfizer. 

vacuna <- sample("pfizer", replace = TRUE)

df_pfizer_RT <- cbind(df_pfizer_RT, vacuna)

vacuna <- sample("sputnikv", replace = TRUE)

df_sputnik_RT <- cbind(df_sputnik_RT, vacuna)

#Uno los df de sputnik y pfizer en uno solo que se va a llamar df.

df_rt <- rbind(df_pfizer_RT, df_sputnik_RT)
```

### Cuantificando tweets por día y vacuna.

Para empezar a analizar un poco los tweets, creemos necesario realizar algunos graficos comparativos que nos permitan sacar conclusiones. En este caso, vamos a enfocarnos en cuantificar la cantidad de tweets que mencionan la vacuna Pfizer como SputnikV, por día y país. 

Como parte de la limpieza de los tweets descargados, decidimos quedarnos unicamente con aquellos países limitrofes a Argentina, salvo Brasil (porque es de habla portuguesa y le pedimos a la api todos los de hispanoparlantes)  

Ahora bien, creemos los df que correspondan a cada país. Para ello, le agregamos una variable nueva, "Pais", donde incorporamos el nombre del país abreviado (que luego nos va a servir para graficar)

```{r include=FALSE}
#Argentina

pais <- sample("ARG", replace = TRUE)

df_argentina_rt <- df_rt %>%
  filter(location %like% "argentina") 
  
df_argentina_rt <- cbind(df_argentina_rt, pais)

#Chile

pais <- sample("CL", replace = TRUE)

df_chile_rt <- df_rt %>%
  filter(location %like% "chile") 

df_chile_rt <- cbind(df_chile_rt, pais)

#Bolivia

pais <- sample("BO", replace = TRUE)

df_bolivia_rt <- df_rt %>%
  filter(location %like% "bolivia")

df_bolivia_rt <- cbind(df_bolivia_rt, pais)

#Paraguay 

pais <- sample("PY", replace = TRUE)

df_paraguay_rt <- df_rt %>%
  filter(location %like% "paraguay") 

df_paraguay_rt <- cbind(df_paraguay_rt, pais)

#Uruguay

pais <- sample("UY", replace = TRUE)

df_uruguay_rt <- df_rt %>%
  filter(location %like% "uruguay")

df_uruguay_rt <- cbind(df_uruguay_rt, pais)

```

Utilicemos la función fn_agrupar para agrupar nuestros df según tipo de vacuna y fecha.

```{r include=FALSE}
#Argentina

contar_arg <- fn_agrupar(df = df_argentina_rt)

#Chile

contar_chl <- fn_agrupar(df = df_chile_rt)

#Paraguay

contar_py <- fn_agrupar(df = df_paraguay_rt)

#Uruguay

contar_uy <- fn_agrupar(df = df_uruguay_rt)

#Bolivia

contar_bo <- fn_agrupar(df = df_bolivia_rt)
```

#### Realicemos graficos para cada país para ver comparar entre las dos vacunas, la cantidad de menciones por día.

##### Argentina

```{r echo=FALSE}
p_diario_arg <- ggplot(contar_arg) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
  theme_minimal()

ggplotly(p_diario_arg)

```


```{r echo=FALSE}
##### Chile

p_diario_ch <- ggplot(contar_chl) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", 
       y = "n tweets", 
       title = "Cantidad de tweets por día y vacuna - Chile") +
  theme_minimal()

ggplotly(p_diario_ch)

```

##### Bolivia

```{r echo=FALSE}
p_diario_bo <- ggplot(contar_bo) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Bolivia") +
  theme_minimal()

ggplotly(p_diario_bo)
```

##### Uruguay

```{r echo=FALSE}

p_diario_uy <- ggplot(contar_uy) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Uruguay") +
  theme_minimal()

ggplotly(p_diario_uy)

```

##### Paraguay

```{r echo=FALSE}
p_diario_py <- ggplot(contar_py) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Paraguay") +
  theme_minimal()

ggplotly(p_diario_py)
```

### Comparemos algunos datos: 

#### Ahora hagamos un gráfico solo donde podemos comparar por país.

Primero unamos los df, donde incluimos una columna de "país"

```{r echo=FALSE}

df_rt <- rbind(df_argentina_rt, df_bolivia_rt, df_chile_rt, df_paraguay_rt, df_uruguay_rt)

contar_tot <- df_rt %>% 
  mutate(created_at = ymd_hms(created_at)) %>%
  mutate(created_at = floor_date(created_at, unit = "day")) %>%
  group_by(vacuna, pais) %>%
  count(created_at) 
  
p_tot <- ggplot(contar_tot) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna") +
 #geom_col(show.legend = FALSE) +
  facet_wrap(~pais, ncol = 2, nrow = 3, scales = "free") +
  theme_minimal()

ggplotly(p_tot)

```

Al comparar los gráficos, podemos observar variaciones en la cantidad de menciones de cada vacuna por país. Esto puede estar relacionado a los acuerdos y vacunas que arribaron o arribarán en cada uno. Lo vemos claramente en Argentina, donde la vacuna SputnikV logra mayor importancia al tener más menciones debido a que es la vacuna que recibiremos, a comparación de Chile que tiene mayores menciones de la vacuna Pfizer ya que es con la que están vacunando.

#### Ahora bien, agreguemos fechas importantes que nos permitan analizar los picos de menciones de la vacuna SputnikV en Argentina: 24 y 29 de diciembre. 

```{r echo=FALSE}
#Agregemos fechas importantes al grafico. El 24 de diciembre trajeron las primeras dosis de la sputnikv y el 29 de diciembre comenzaron con la vacunación.

fecha_dosis_sputnik <- ymd("2020-12-24")
fecha_vacunacion_sputnik <- ymd("2020-12-29")

p_hitos_arg <- ggplot(contar_arg) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  geom_text(aes( x=created_at, y=n, label=n), size=3, fontface="italic") +
  scale_x_datetime(date_labels = "%d-%m", date_breaks = "3 day") +
  labs(x = "Fecha", y = "Número de tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
  geom_vline(aes(xintercept = as.POSIXct(fecha_dosis_sputnik)),
             color = "orange", alpha = .7)  +
  geom_vline(aes(xintercept = as.POSIXct(fecha_vacunacion_sputnik)),
             color = "orange", alpha = .7)  +
  theme_minimal() 

p_hitos_arg

ggsave("p_hitos_arg.png")

```

Antes de seguir, analicemos un poco lo que vimos recien: de la visualización general de los datos se puede observar que los picos de tweets coinciden con dos sucesos de importancia para la opinión pública: el arribo de la vacuna sputnikV a Argentina el dia 24/12/20 con 4023 tweets y con el día de inicio de la vacunación el día 29/12/20 con 4399 tweets. 

Por otro lado, también se observa que si bien la vacuna Pfizer no pudo ser traída a Argentina ni mucho menos empezar un esquema de vacunación para la población, los tweets que la mencionan coinciden con la fecha relevante para la vacuna sputnikV (29/12/20). De esta forma, se podría pensar que hay una relación simétrica entre las menciones de la vacuna sputnik y la vacuna de Pfizer. Esta cuestión, podría deberse al alto grado de polarización y politización mediática que existe entre la eficacia y utilización de ambas vacunas. 

Ahora bien, indaguemos un poco la dinamica de twitter en relación a nuestro dataset Argentino. En este paso vamos a usar el df que une los tweets de pfizer y sputnik - DF ARGENTINA, que incluye los RT.

```{r echo=FALSE}
#Eliminar rt y respuestas. 

df_organicos_arg <- df_argentina_rt %>%
  subset(is.na(reply_to_status_id)) %>%
  filter(is_retweet == FALSE) 

#Nos quedamos solo con los rt

df_rtweets_arg <- df_argentina_rt %>%
  filter(is_retweet==TRUE)

#Nos quedamos solo con las respuestas

df_respuestas_arg <- df_argentina_rt %>% subset(!is.na(reply_to_status_id))

#Creo un marco con la cantidad de rt, organico y respuestas

categorias_arg <- data.frame(category = c ("Organico", "Retweets", "Respuestas"),
                            count=c(7215, 37506, 2834))

#Calculamos la fracción que hay de cada categoria

categorias_arg$fraction = categorias_arg$count / sum(categorias_arg$count)

#Calculamos el porcentaje que hay de cada categoria

categorias_arg$percentage = categorias_arg$count / sum(categorias_arg$count) * 100

#Redondeamos el porcentaje de la columna 4 (percentage)
categorias_arg[,4] <-round(categorias_arg[,4],0) 

ggplot(categorias_arg) +
  geom_bar(mapping = aes(x= category, y = percentage, fill = category), stat = "identity") +
  scale_fill_brewer(palette = "Accent") +
  labs(x = "Categoria", y = "Porcentaje", title = "Porcentaje de tweets por categoría") +
  geom_text(aes(x=category, y=percentage, label=percentage), size=3)
```

Cuando se analiza a los tweets por categoría, dividiendolos en tres categorías, condiseramos a: orgánicos como los tweets “originales”, “respuestas” a las respuestas de los tweets que mencionan a las vacunas y “retweets” (valga la redundancia) a los retweets.

Aqui se observa que la mayor cantidad de tweets, son retweets (79%). Esta cuestión nos muestra que el efecto cascada realizado por líderes de opinión (calvo, 2015) es muy fuerte, ya que los tweets originales solo corresponden al 15 %.

## Tweets con más rt y más favs. 

Para realizar este analisis, debemos utilizar df sin RT. Para ello, realizamos el df global, y luego a parte, lo filtramos por los valores que son de nuestro interes.

```{r include=FALSE}
#df base sin rt

df_nort <- df_rt %>%
  filter(is_retweet == FALSE)

```

### Pfizer

```{r include=FALSE}
#Creamos un df con datos de argentina que nos sirva para realizar luego el analisis de stop words. Pfizer
df_arg_noRT_pfizer <- df_nort %>%
  filter(location %like% "argentina" & vacuna == "pfizer") 

#Filtramos
count_arg_pfizer <- df_arg_noRT_pfizer %>%
  select(screen_name, text, retweet_count, favorite_count, followers_count, verified) %>%
  filter(retweet_count >= 100 | favorite_count >= 300) %>%
  arrange(desc(retweet_count))

view(count_arg_pfizer)
```

El tweet con más rt y más favoritos de nuestro dataset de pfizer es el de Vivaroca2015: 

"el único país con el que pfizer tiene problemas es argentina pero alberto pretende que le creamos que la culpa es del laboratorio en verdad piensa que todos tenemos el mismo nivel intelectual de sus votantes"
Si bien no es una cuenta verificada, observamos que tiene 45672 followers, por lo tanto, una gran llegada en la red social.

El tweet que le sigue según favoritos es guarda_la_moto con:

"estamos negociando con pfizer pero ellos tienen algunos problemas logísticos tienen que pedirle permiso al que tiene sombrero de mapache primero"

Sin embargo, la cantidad de rt no es significante.

El siguiente tweet más rt es el de edufeiok: 

"esta gente es muy delirante se pasan de listos con el relato un médico asesor de axel kicillof dijo que pfizer pidió de garantía glaciares y permisos de pesca para traer su vacuna al país".

En este caso, si es una cuenta verificada, con 711125 de followers. 

### SputnikV

```{r include=FALSE}
#Creamos un df con datos de argentina que nos sirva para realizar luego el analisis de stop words. SputnikV

df_arg_noRT_sputnik <- df_nort %>%
  filter(location %like% "argentina" & vacuna == "sputnikv")

#Filtramos
count_arg_sputnik <- df_arg_noRT_sputnik %>%
  select(screen_name, text, retweet_count, favorite_count, followers_count, verified) %>%
  filter(retweet_count >= 100 | favorite_count >= 300) %>%
  arrange(desc(retweet_count))

view(count_arg_sputnik)
```

En el caso de sputnik, el tweet con más rt y favoritos es de carlavizzotti:

"el gobierno argentino adquirió al fondo de inversión directa de rusia millones de esquemas de vacuna sputnik v millones de dosis que llegarán en función del contrato firmado entre los meses de diciembre y marzo" 

Su cuenta es verificada y tiene 42121 seguidores.

El segundo tweet con más favoritos, pero pocos rt, es gonchobanzas, con 329374 seguidores.

"me vacuné con la sputnik y esta todo bien adjunto selfie" 

## Analisis de las palabras más mencionadas en los tweets.

Vamos a realizar un analisis de las palabras más mencionadas, tanto para los tweets que mencionan a pfizer como para los que mencionan a sputnikV. Para eso utilizaremos el df sin rt de argentina.

Bien, ahora genero un corpus con todas las palabras, para cada país. Utilizo la función fn_tokenizar

```{r include=FALSE}
#genero un dataset que tenga todas las palabras de los tweets, 1 por fila, utilizando la función creada anteriormente "fn_tokenizar"

#Pfizer

token_pfizer_arg <- fn_tokenizar(tk = df_arg_noRT_pfizer)

#SputnikV

token_sputnik_arg <- fn_tokenizar(tk = df_arg_noRT_sputnik)

```

Ahora bien, realicemos el analisis de las palabras más mencionadas. Primero creamos un df con los stops words

```{r include=FALSE}
# Genero dataframe especial con stop words en español, de la librería tm

custom_stop_words <- bind_rows(stop_words,
                               data_frame(word = tm::stopwords("spanish"), lexicon = "custom"))

# Veo las stopwords

#unique(custom_stop_words$word)

#Realicemos tambien un listado de stop words que no aportan a nuestro analisis

palabras_sinaporte <- tibble(word = c("vacunas", "si", "informa", "a", "aa", "acá"))

```

Bien, ahora saco los stop words

```{r include=FALSE}
#Argentina 1. sputnik, 2. pfizer

token_sputnik_arg <- token_sputnik_arg %>% 
  anti_join(custom_stop_words) %>%
  anti_join(palabras_sinaporte)

token_pfizer_arg <- token_pfizer_arg %>%
  anti_join(custom_stop_words) %>%
  anti_join(palabras_sinaporte)
```


Ahora veamos la frecuencia de palabras en el corpus a traves de la función fn_frecuencia

```{r include=FALSE}
#Pfizer

fn_frecuencia(frec = token_pfizer_arg)

#SputnikV

fn_frecuencia(frec = token_sputnik_arg)
```

Ploteamos las palabras más frecuentes

### Pfizer

```{r echo=FALSE}
# Ploteamos las palabras más frecuentes

token_pfizer_arg %>%
  count(word, sort = TRUE) %>%
  filter(n > 200 & n < 2000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = word)) +
  geom_col() +
  labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre Pfizer", subtitle = "Argentina") + 
  xlab(NULL) +
  scale_fill_brewer(palette = "Spectral") +
  geom_text(aes( x=word, y=n, label=n), size=3) +
  coord_flip()
```

En cuanto al análisis de las palabras que se utilizan más frecuentemente, se observa, descartando la primera plabra más utilizada, “Pfizer” con 2799 observaciones, le sigue “vacuna” con 1274 observaciones. La tercer palabra más utilizada es “sputnik” con 309 observaciones. Esta situación, sugiere que cuando se refieren a Pfizer se la contrapone frente a otra. Esta última consideración podría reafirmar la conjetura sobre la polarización y politización existente entre el uso o no de una o otra vacuna. 

### SputnikV

```{r echo=FALSE}
# Ploteamos las palabras más frecuentes
token_sputnik_arg %>%
  count(word, sort = TRUE) %>%
  filter(n > 600 & n < 6000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = word)) +
  geom_col() +
  labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre SputnikV", subtitle = "Argentina") +
  xlab(NULL) +
  scale_fill_brewer(palette = "Spectral") +
  geom_text(aes( x=word, y=n, label=n), size=3) +
  coord_flip()

```

Al igual que Pfizer, la primera  palabra más utilizada es el nombre de la vacuna con 6551 observaciones y la palabra “vacuna” con 2882 observaciones. Ahora bien, lo que sí llama la atención, es que a diferencia de la Pfizer, aparecen dos países con una cantidad de menciones alta:  Rusia con 630 y Argentina 602 observaciones. Esta evidencia, muestra que la politización y polarización alrededor de la vacuna Sputnik V ocurre fuertemente.Incluso si uno observa la nube de palabras pugede encontrar que aparecen varios nombres de funcionarios de este país como “ginés”, “kicillof”, “vizzoti”.

## WordCloud

Realicemos una WordCloud para cada vacuna, montrando las palabras que se mencionan en los tweets.

### Pfizer

```{r echo=FALSE}
# Word cloud

token_pfizer_arg %>%
  count(word, sort=T) %>%
  filter(n < 2000) %>% #eliminamos la palabra pfizer de la nube
  wordcloud2(size = 1, color = 'random-light', backgroundColor = "black")

```

### Sputnik V

```{r echo=FALSE}
# Word cloud

token_sputnik_arg %>%
  count(word, sort=T) %>%
  filter(n < 6000) %>% #eliminamos la palabra sputnik de la nube
  wordcloud2(size = 1, color = 'random-light', backgroundColor = "black")

```

### Calculemos el tf-idf

```{r echo=FALSE}
# Calculemos la cantidad de palabras por vacuna SputnikV

token_sp <- token_sputnik_arg %>%
  count(vacuna, word, sort = TRUE) %>%
  filter(n > 50)

#Calculamos la cantidad de palabras por la vacuna Pfizer

token_pf <- token_pfizer_arg %>%
  count(vacuna, word, sort = TRUE) %>%
  filter(n > 50)

# Uno los df

token_agrupado <- rbind(token_sp, token_pf)

total_palabras <- token_agrupado %>% 
  group_by(vacuna) %>% 
  summarize(total = sum(n))

token_agrupado <- left_join(token_agrupado, total_palabras)

#Ahora calculamos el tf-idf 

token_agrupado <- token_agrupado %>%
  bind_tf_idf(word, vacuna , n)

#Hagamos el plot

token_agrupado %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(vacuna) %>%
  top_n(15) %>% 
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = vacuna)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~vacuna, ncol = 2, scales = "free") +
  coord_flip()

```

### Sentiment Analisys 

Ahora realizemos un sentiment analisys para ver cuál es el sentimiento mayoritario. 

```{r include=FALSE}
sentimientos <- read_tsv("https://raw.githubusercontent.com/7PartidasDigital/AnaText/master/datos/diccionarios/sentimientos_2.txt",col_types = "cccn", locale = default_locale())

sentimientos <- sentimientos %>% rename(word=palabra)

source("https://raw.githubusercontent.com/7PartidasDigital/R-LINHD-18/master/get_sentiments.R")

```

Cruzo con mi lexicón de sentimientos y empiezo a ver la distribución de sentimientos en los discursos

```{r echo=FALSE}
#Con NRC

token_agrupado %>%
  right_join(get_sentiments("nrc")) %>%
  filter(!is.na(sentimiento)) %>%
  count(sentimiento, sort = TRUE)

# Pruebo con bing para todo el corpus
token_agrupado %>%
  right_join(get_sentiments("bing")) %>%
  filter(!is.na(sentimiento)) %>%
  count(sentimiento, sort = TRUE)

# Ploteo por NRC 

token_agrupado %>%
  right_join(get_sentiments("nrc")) %>%
  na.omit() %>%
  filter(sentimiento != "negativo" & sentimiento !="positivo" & sentimiento != "disgusto") %>%
  count(vacuna, sentimiento, sort = TRUE) %>%
  ggplot(aes(sentimiento, n, fill = sentimiento)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_brewer(palette = "Paired") +
  theme_minimal() +
  facet_wrap(~vacuna, ncol = 2, scales = "free_x")+
  coord_flip()

#Ploteo por bing

token_agrupado %>%
  right_join(get_sentiments("bing")) %>%
  na.omit() %>%
  count(vacuna, sentimiento, sort = TRUE) %>%
  arrange(vacuna, desc(n), sentimiento) %>% 
  ggplot(aes(vacuna, n, fill = sentimiento)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Pastel2") +
  theme_minimal() +
  facet_wrap(~vacuna, ncol = 2, scales = "free_x")


```                         

### Topic modeling

Vamos a realizar un topic modeling para los tweets con ubicación en Argentina.

### Pfizer

Para realizar topic modeling primero debo generar una matriz término-documento.

```{r include=FALSE}
#Genero la matriz término documento con la función ```cast_dtm()```

data_conteo_pfizer <- token_pfizer_arg %>% count(status_id, word, sort=TRUE)

data_dtm_pfizer <- data_conteo_pfizer %>%
  cast_dtm(status_id, word, n)

data_dtm_pfizer $nrow
data_dtm_pfizer $ncol

```

Ahora aplico mi topic modelling y utilizo la función ```LDA()``` (latent dirichlet allocation)

```{r echo=FALSE}
# Con k indico la cantidad de tópicos

data_lda_pfizer <- LDA(data_dtm_pfizer, k = 4, control = list(seed = 150))

# Paso el objeto a tidy, beta son las probabilidades per-topic-per-word

data_lda_td_pfizer <- tidy(data_lda_pfizer, matrix = "beta")

# Veo los términos más frecuentes de mi topic modelling
terminos_frecuentes_pfizer <- data_lda_td_pfizer %>%
  group_by(topic) %>%
  top_n(20, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Ploteo mis tópicos
terminos_frecuentes_pfizer %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  labs(title = "Tópicos") +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

### Sputnik

Genero la matriz término documento 

```{r include=FALSE}
data_conteo_sputnik <- token_sputnik_arg %>% count(status_id, word, sort=TRUE)

data_dtm_sputnik <- data_conteo_sputnik %>%
  cast_dtm(status_id, word, n)

data_dtm_sputnik $nrow
data_dtm_sputnik $ncol

```

Ahora aplico mi topic modelling

```{r echo=FALSE}
# Con k indico la cantidad de tópicos

data_lda_sputnik <- LDA(data_dtm_sputnik, k = 4, control = list(seed = 150))

# Paso el objeto a tidy, beta son las probabilidades per-topic-per-word

data_lda_td_sputnik <- tidy(data_lda_sputnik, matrix = "beta")

# Veo los términos más frecuentes de mi topic modelling
terminos_frecuentes_sputnik <- data_lda_td_sputnik %>%
  group_by(topic) %>%
  top_n(20, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Ploteo mis tópicos
terminos_frecuentes_sputnik %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  labs(title = "Tópicos") +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

