---
title: 'Analizando twitter: menciones de las vacunas Pfizer y SputnikV'
author: "Eugenia Hernandez + Santiago Caviglia + Fernando Zaffaroni + Ornella Giansetto + Walter Baez"
date: "1/1/2021"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(lubridate)
library(data.table)
library(ggplot2)
library(plotly)
library(tm)
library(tidytext)
library(wordcloud2)
#install.packages("webshot")
library(webshot)
library(htmlwidgets)
library(RColorBrewer)
library(topicmodels)
library(knitr)
```

En el siguiente trabajo analizaremos las menciones que reciben las vacunas SputnikV y Pfizer en twitter. Para ello, descargamos cada dos días 18.000 mil tweets, por vacuna. Luego filtramos por los países que son de nuestro interes:  los países limítrofes a Argentina, dejando de lado a Brasil ya que su idioma es el portugues.

A través de dichos tweets buscabamos analizar varias cosas: 

1. Por un lado, cuantificar las menciones por día que se realizaban de cada vacuna y para cada país limítrofe a Argentina. A su vez, al gráfico de Argentina le agregamos hitos que nos daban una respuesta a los picos de menciones.

2. Por otro lado, quisimos analizar cuál era la dinámica en twitter para tratar de entender cómo se forman/llevan adelante las conversaciones. 

    2.1 Dado que la mayoría de los tweets que circulan son retweets, quisimos tratar de entender quienes eran los formadores de opinión (siempre dentro de nuestro dataset)

3. Asimismo, analizamos cuáles son las palabras que se utilizan con más frecuencia cuando se menciona a una u otra vacuna. 

4. Analizamos también cuáles eran los sentimientos que se desprenden de dichos tweets.


```{r include=FALSE}
#Cargo los df

#Usamos "../" como una via alternativa para leer el csv desde cualquier equipo, sin importar en que carpeta descargue cada uno el proyecto. 

df_pfizer_RT <- read.csv2("../Data/df_pfizer_RT_final.csv")
df_sputnik_RT <- read.csv2("../Data/df_sputnik_RT_final.csv")

```

En primer lugar, creamos las funciones que son necesarias para realizar el analisis.

1. Función para agrupar los df por tipo de vacuna 

2. Función para tokenizar los df

3. Función para contar la frecuencia de las palabras

```{r include=FALSE}
#Creamos nuestras funciones 

#Creamos una función para agrupar los df por tipo de vacuna y contar el n por fecha

fn_agrupar <- function(df) {
  df <- df %>% mutate(created_at = ymd_hms(created_at)) 
  df <- df %>% mutate(created_at = floor_date(created_at, unit = "day"))
  #Agrupamos los tweets por tipo de vacuna
  df <- df %>% group_by(vacuna) 
  #Contamos los tweets por día y tipo
  df <- df %>% count(created_at) 
  return(df)
}

#Creamos una función para tokenizar nuestros datasets. 

fn_tokenizar <- function(tk) {
  tk <- tk %>% unnest_tokens(word,text)
  return(tk)
}

#Creamos una función para contar la frecuencia de palabras

fn_frecuencia <- function(frec) {
  frec <- frec %>% count(word, sort = TRUE)
  print(frec)
}

```

Antes de comenzar con el analisis, preparemos nuestro dataset. Para ello vamos a utilizar los df CON Retweet. A cada df le creamos una columna con el nombre "tipo" donde le diremos si es sputnikV o pfizer. Luego, unimos ambos df en uno solo final.

```{r include=FALSE}

#Creo una columna nueva llamada "tipo" en los df con RT donde se va a aclarar si habla sobre la vacuna sputnikv o pfizer. 

vacuna <- sample("pfizer", replace = TRUE)

df_pfizer_RT <- cbind(df_pfizer_RT, vacuna)

vacuna <- sample("sputnikv", replace = TRUE)

df_sputnik_RT <- cbind(df_sputnik_RT, vacuna)

#Uno los df de sputnik y pfizer en uno solo que se va a llamar df.

df_rt <- rbind(df_pfizer_RT, df_sputnik_RT)
```

### Cuantificando tweets por día y vacuna.

Para empezar a analizar un poco los tweets, creemos necesario realizar algunos gráficos comparativos que nos permitan sacar conclusiones. En este caso, vamos a enfocarnos en cuantificar la cantidad de tweets que mencionan por un lado a la vacuna Pfizer y por el otro a SputnikV, por día y país. 

Como parte de la limpieza de los tweets descargados, decidimos quedarnos unicamente con aquellos países limitrofes a Argentina, salvo Brasil (porque hablan portugues y le pedimos a la api todos los de hispanoparlantes)  

Ahora bien, creemos los df que corresponden a cada país. Para ello, le agregamos una variable nueva, "Pais", donde incorporamos el nombre del país abreviado (que luego nos va a servir para graficar) 

Luego utilizamos la función agrupar para agrupar nuestros df según tipo de vacuna y fecha. 

```{r include=FALSE}
#Argentina

pais <- sample("ARG", replace = TRUE)

df_argentina_rt <- df_rt %>%
  filter(location %like% "argentina") 
  
df_argentina_rt <- cbind(df_argentina_rt, pais)

#Chile

pais <- sample("CL", replace = TRUE)

df_chile_rt <- df_rt %>%
  filter(location %like% "chile") 

df_chile_rt <- cbind(df_chile_rt, pais)

#Bolivia

pais <- sample("BO", replace = TRUE)

df_bolivia_rt <- df_rt %>%
  filter(location %like% "bolivia")

df_bolivia_rt <- cbind(df_bolivia_rt, pais)

#Paraguay 

pais <- sample("PY", replace = TRUE)

df_paraguay_rt <- df_rt %>%
  filter(location %like% "paraguay") 

df_paraguay_rt <- cbind(df_paraguay_rt, pais)

#Uruguay

pais <- sample("UY", replace = TRUE)

df_uruguay_rt <- df_rt %>%
  filter(location %like% "uruguay")

df_uruguay_rt <- cbind(df_uruguay_rt, pais)

```

```{r include=FALSE}
#Utilicemos la función fn_agrupar para agrupar nuestros df según tipo de vacuna y fecha.

#Argentina

contar_arg <- fn_agrupar(df = df_argentina_rt)

#Chile

contar_chl <- fn_agrupar(df = df_chile_rt)

#Paraguay

contar_py <- fn_agrupar(df = df_paraguay_rt)

#Uruguay

contar_uy <- fn_agrupar(df = df_uruguay_rt)

#Bolivia

contar_bo <- fn_agrupar(df = df_bolivia_rt)
```

#### Realicemos graficos para cada país para comparar entre las dos vacunas, la cantidad de menciones por día.

Bien, aqui realizaremos los gráficos de línea correspondientes a cada país según la cantidad de menciones por día por vacuna. 

##### Argentina

```{r echo=FALSE}
p_diario_arg <- ggplot(contar_arg) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
  theme_minimal()

ggplotly(p_diario_arg)

```

En el gráfico podemos observar picos de menciones de la vacuna SputnikV los días 24 y 29 de Diciembre, y 3, 5 y 12 de enero. 

##### Chile

```{r echo=FALSE}
p_diario_ch <- ggplot(contar_chl) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", 
       y = "n tweets", 
       title = "Cantidad de tweets por día y vacuna - Chile") +
  theme_minimal()

ggplotly(p_diario_ch)

```

En el caso de Chile, los picos de menciones corresponden a la vacuna Pfizer, por el contrario de Argentina.

##### Bolivia

```{r echo=FALSE}
p_diario_bo <- ggplot(contar_bo) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Bolivia") +
  theme_minimal()

ggplotly(p_diario_bo)
```

Si observamos el gráfico de Bolivia, vemos que la cantidad de tweets con ubicación "Bolivia" es mucho menor a otros países limítrofes, sin embargo, igualmente se puede observar qué vacuna recibe más menciones. En este caso vemos que los picos de menciones corresponden a la vacuna SputnikV.

##### Uruguay

```{r echo=FALSE}

p_diario_uy <- ggplot(contar_uy) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Uruguay") +
  theme_minimal()

ggplotly(p_diario_uy)

```
Uruguay, a diferencia de los demás países, tiene fluctuaciones de menciones de ambas vacunas. No hay ninguna vacuna que prevalece sobre la otra, sino que dependiendo de la fecha son los picos de las menciones de ambas vacunas.

##### Paraguay

```{r echo=FALSE}
p_diario_py <- ggplot(contar_py) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x = "Fecha", y = "n tweets", title = "Cantidad de tweets por día y vacuna - Paraguay") +
  theme_minimal()

ggplotly(p_diario_py)
```

En el caso de Paraguay, observamos que en diciembre hay más menciones de la vacuna Pfizer, pero en enero las menciones de SputnikV llegan a un pico muy alto, probablemente por algún anuncio que haya realizado el presidente con respecto a esa vacuna.

### Comparemos algunos datos: 

#### Ahora hagamos un gráfico solo donde podemos comparar entre país.

Para poder comparar entre países creemos necesario realizar un gráfico solo que una a todos.

```{r echo=FALSE}
#Primero unamos los df:

df_rt <- rbind(df_argentina_rt, df_bolivia_rt, df_chile_rt, df_paraguay_rt, df_uruguay_rt)

contar_tot <- df_rt %>% 
  mutate(created_at = ymd_hms(created_at)) %>%
  mutate(created_at = floor_date(created_at, unit = "day")) %>%
  group_by(vacuna, pais) %>%
  count(created_at) 
  
p_tot <- ggplot(contar_tot) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  labs(x="fecha", y = "n", title = "Cantidad de tweets por día y vacuna") +
  facet_wrap(~pais, ncol = 2, nrow = 3, scales = "free") +
  theme_minimal()

ggplotly(p_tot)

```

Al comparar los gráficos, podemos observar variaciones en la cantidad de menciones de cada vacuna por país. Esto puede estar relacionado a los acuerdos y vacunas que arribaron o arribarán a cada uno. Lo vemos claramente en Argentina, donde la vacuna SputnikV logra mayor importancia al tener más menciones debido a que es la vacuna que recibimos, a comparación de Chile que tiene mayores menciones de la vacuna Pfizer ya que es con la que están vacunando.

#### Fechas importantes

Ahora bien, agreguemos fechas importantes que nos permitan analizar los picos de menciones de la vacuna SputnikV en Argentina: 24 y 29 de diciembre. 

```{r echo=FALSE}
#Agregemos fechas importantes al grafico. El 24 de diciembre trajeron las primeras dosis de la sputnikv y el 29 de diciembre comenzaron con la vacunación.

fecha_dosis_sputnik <- ymd("2020-12-24")
fecha_vacunacion_sputnik <- ymd("2020-12-29")

p_hitos_arg <- ggplot(contar_arg) +
  geom_line(aes(x = created_at, y = n, color = vacuna)) +
  geom_text(aes( x = created_at, y=n, label=n), size=3, fontface="italic") +
  scale_x_datetime(date_labels = "%d-%m", date_breaks = "3 day") +
  labs(x = "Fecha", y = "Número de tweets", title = "Cantidad de tweets por día y vacuna - Argentina") +
  geom_vline(aes(xintercept = as.POSIXct(fecha_dosis_sputnik)),
             color = "orange", alpha = .7)  +
  geom_vline(aes(xintercept = as.POSIXct(fecha_vacunacion_sputnik)),
             color = "orange", alpha = .7)  +
  theme_minimal() 

p_hitos_arg


```

Antes de seguir, analicemos un poco lo que vimos recien: de la visualización general de los datos se puede observar que los picos de tweets coinciden con dos sucesos de importancia para la opinión pública: el arribo de la vacuna sputnikV a Argentina el dia 24/12/20 con 4023 tweets y con el día de inicio de la vacunación el día 29/12/20 con 4399 tweets. 

Por otro lado, también se observa que si bien la vacuna Pfizer no pudo ser traída a Argentina ni mucho menos empezar un esquema de vacunación para la población, los tweets que la mencionan coinciden con la fecha relevante para la vacuna sputnikV (29/12/20). De esta forma, se podría pensar que hay una relación simétrica entre las menciones de la vacuna sputnik y la vacuna de Pfizer. Esta cuestión, podría deberse al alto grado de polarización y politización mediática que existe entre la eficacia y utilización de ambas vacunas. 

### Dinámica 

Ahora bien, indaguemos un poco la dinámica de twitter en relación a nuestro dataset Argentino. En este paso vamos a usar el df que une los tweets de pfizer y sputnik - DF ARGENTINA, que incluye los RT.

```{r echo=FALSE}
#Eliminar rt y respuestas. 

df_organicos_arg <- df_argentina_rt %>%
  subset(is.na(reply_to_status_id)) %>%
  filter(is_retweet == FALSE) 

#Nos quedamos solo con los rt

df_rtweets_arg <- df_argentina_rt %>%
  filter(is_retweet==TRUE)

#Nos quedamos solo con las respuestas

df_respuestas_arg <- df_argentina_rt %>% subset(!is.na(reply_to_status_id))

#Creo un marco con la cantidad de rt, organico y respuestas

categorias_arg <- data.frame(category = c ("Organico", "Retweets", "Respuestas"),
                            count=c(7215, 37506, 2834))

#Calculamos la fracción que hay de cada categoria

categorias_arg$fraction = categorias_arg$count / sum(categorias_arg$count)

#Calculamos el porcentaje que hay de cada categoria

categorias_arg$percentage = categorias_arg$count / sum(categorias_arg$count) * 100

#Redondeamos el porcentaje de la columna 4 (percentage)
categorias_arg[,4] <-round(categorias_arg[,4],0) 

ggplot(categorias_arg) +
  geom_bar(mapping = aes(x= category, y = percentage, fill = category), stat = "identity") +
  scale_fill_brewer(palette = "Accent") +
  labs(x = "Categoria", y = "Porcentaje", title = "Porcentaje de tweets por categoría") +
  geom_text(aes(x=category, y=percentage, label=percentage), size=3)
```

Cuando se analiza a los tweets por categoría, dividiendolos en tres, condiseramos a: orgánicos como los tweets “originales”, “respuestas” a las respuestas de los tweets que mencionan a las vacunas y “retweets” (valga la redundancia) a los retweets.

Aqui podemos ver claramente que la dinámica de twitter no es publicar tweets nuevos, sino retwittear aquellos que se volvieron virales. En este sentido, se observa que la mayor cantidad de tweets, son retweets (79%). Esta cuestión nos muestra que el efecto cascada realizado por líderes de opinión (calvo, 2015) es muy fuerte, ya que los tweets originales solo corresponden al 15 %.

## Tweets con más rt y más favs. 

Ahora bien, dado que observamos un efecto cascada, nos pareció interesante analizar cuáles son los tweets con más rt y más favoritos. Este análisis lo realizaremos unicamente para aquellos cuya ubicación es Argentina.

Para realizar este análisis, debemos utilizar df sin RT. Para ello, utilizamos el df global ya armado con RT y le borramos todos los rt. Luego lo filtramos por los valores que son de nuestro interes.

```{r include=FALSE}
#df base sin rt

df_nort <- df_rt %>%
  filter(is_retweet == FALSE)

```

Ahora bien, para poder realizar mejor el análisis, vamos a separar nuestro df según la vacuna. 

### Pfizer

En este caso, nos quedamos con todos los tweets con ubicación en argentina, que mencionan a la vacuna Pfizer y que tengan más de 100 rt ó 300 favs.

```{r include=FALSE}
#Creamos un df con datos de argentina que nos sirva para realizar luego el analisis de stop words. Pfizer
df_arg_noRT_pfizer <- df_nort %>%
  filter(location %like% "argentina" & vacuna == "pfizer") 

#Filtramos
count_arg_pfizer <- df_arg_noRT_pfizer %>%
  select(screen_name, text, retweet_count, favorite_count, followers_count, verified) %>%
  filter(retweet_count >= 100 | favorite_count >= 300) %>%
  arrange(desc(retweet_count))

view(count_arg_pfizer)
```

El tweet con más rt y más favoritos de nuestro dataset de pfizer es el de Vivaroca2015: 

1. "el único país con el que pfizer tiene problemas es argentina pero alberto pretende que le creamos que la culpa es del laboratorio en verdad piensa que todos tenemos el mismo nivel intelectual de sus votantes"
Si bien no es una cuenta verificada, observamos que tiene 45672 followers, por lo tanto, una gran llegada en la red social.

El tweet que le sigue según favoritos es guarda_la_moto con:

2. "estamos negociando con pfizer pero ellos tienen algunos problemas logísticos tienen que pedirle permiso al que tiene sombrero de mapache primero"

Sin embargo, para el tweet de guarda_la_moto la cantidad de rt no es significante.

El siguiente tweet más rt es el de edufeiok: 

3. "esta gente es muy delirante se pasan de listos con el relato un médico asesor de axel kicillof dijo que pfizer pidió de garantía glaciares y permisos de pesca para traer su vacuna al país".

En este caso, estamos hablando de cuentas con influencia ya que está verificada, con 711125 de followers. 

### SputnikV

Ahora sigamos por las menciones a SputnikV. 

En este caso, nos quedamos con todos los tweets con ubicación en argentina, que mencionan a la vacuna sputnikV y que tengan más de 100 rt ó 300 favs.

```{r include=FALSE}
#Creamos un df con datos de argentina que nos sirva para realizar luego el analisis de stop words. SputnikV

df_arg_noRT_sputnik <- df_nort %>%
  filter(location %like% "argentina" & vacuna == "sputnikv")

#Filtramos
count_arg_sputnik <- df_arg_noRT_sputnik %>%
  select(screen_name, text, retweet_count, favorite_count, followers_count, verified) %>%
  filter(retweet_count >= 100 | favorite_count >= 300) %>%
  arrange(desc(retweet_count))

view(count_arg_sputnik)
```

En el caso de sputnik, el tweet con más rt y favoritos es de carlavizzotti:

1. "el gobierno argentino adquirió al fondo de inversión directa de rusia millones de esquemas de vacuna sputnik v millones de dosis que llegarán en función del contrato firmado entre los meses de diciembre y marzo" 

Su cuenta es verificada y tiene 42121 seguidores por lo que claramente tiene una gran llegada a la comunidad.

El segundo tweet con más favoritos, pero pocos rt, es gonchobanzas, con 329374 seguidores.

2. "me vacuné con la sputnik y esta todo bien adjunto selfie" 

## Analisis de las palabras más mencionadas en los tweets.

Ahora bien, vamos a realizar un análisis de las palábras más mencionadas, tanto para los tweets que mencionan a pfizer como para los que mencionan a sputnikV. Para eso utilizaremos el df sin rt de Argentina.

Los pasos a seguir son los siguientes:

1. Genero un corpus con todas las palábras, para cada país. Para ello utilizo la función tokenizar.

2. Creamos un df con los stops words en español.

3. Realizamos un listado de stop words que no aportan a nuestro analisis y no fueron incluidas en el paso anterior.

4. Sacamos las stop words que no ayudan al análisis.

5. Vemos la frecuencia de las palabras en el corpus a traves de la función fn_frecuencia

6. Ploteamos.

```{r include=FALSE}
#Genero un dataset que tenga todas las palabras de los tweets, 1 por fila, utilizando la función creada anteriormente "fn_tokenizar"

#Pfizer

token_pfizer_arg <- fn_tokenizar(tk = df_arg_noRT_pfizer)

#SputnikV

token_sputnik_arg <- fn_tokenizar(tk = df_arg_noRT_sputnik)

```

```{r include=FALSE}
#Genero dataframe especial con stop words en español, de la librería tm

custom_stop_words <- bind_rows(stop_words,
                               data_frame(word = tm::stopwords("spanish"), lexicon = "custom"))

# Veo las stopwords

#unique(custom_stop_words$word)

#Realicemos tambien un listado de stop words que no aportan a nuestro analisis

palabras_sinaporte <- tibble(word = c("vacunas", "si", "informa", "a", "aa", "acá"))

```

```{r include=FALSE}

#Bien, ahora saco los stop words

#Argentina 1. sputnik, 2. pfizer

token_sputnik_arg <- token_sputnik_arg %>% 
  anti_join(custom_stop_words) %>%
  anti_join(palabras_sinaporte)

token_pfizer_arg <- token_pfizer_arg %>%
  anti_join(custom_stop_words) %>%
  anti_join(palabras_sinaporte)
```

```{r include=FALSE}
#Frecuencia de palabras

#Pfizer

fn_frecuencia(frec = token_pfizer_arg)

#SputnikV

fn_frecuencia(frec = token_sputnik_arg)
```

### Ploteamos las palabras más frecuentes

#### Pfizer

Ploteamos las palabras más frecuentes entre los tweets que mencionan a Pfizer y tienen ubicación en Argentina.

```{r echo=FALSE}
# Ploteamos las palabras más frecuentes

token_pfizer_arg %>%
  count(word, sort = TRUE) %>%
  filter(n > 200 & n < 2000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = word)) +
  geom_col() +
  labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre Pfizer", subtitle = "Argentina") + 
  xlab(NULL) +
  scale_fill_brewer(palette = "Spectral") +
  geom_text(aes( x=word, y=n, label=n), size=3) +
  coord_flip()
```

En cuanto al análisis de las palabras que se utilizan más frecuentemente, se observa, descartando la primera plabra más utilizada, “Pfizer” con 2799 observaciones, le sigue “vacuna” con 1274 observaciones. La tercer palabra más utilizada es “sputnik” con 309 observaciones. Esta situación, sugiere que cuando se refieren a Pfizer se la contrapone frente a otra. Esta última consideración podría reafirmar la conjetura sobre la polarización y politización existente entre el uso o no de una o otra vacuna. 

Ahora graficamos las palabras utilizadas pero a traves de una nube de palabras.

#### Wordcloud

```{r echo=FALSE}
# Word cloud

wordcloud_pf <- token_pfizer_arg %>%
  count(word, sort=T) %>%
  filter(n < 2000) %>% #eliminamos la palabra pfizer de la nube
  wordcloud2(size = 1, color = 'random-light', backgroundColor = "black")

wordcloud_pf

```

La nube de palabras nos muestra, al igual que el gráfico anterior, que la palabra más mencionada es "Vacuna".

#### SputnikV

Ploteamos las palabras más frecuentes entre los tweets que mencionan a SputnikV  y tienen ubicación en Argentina.

```{r echo=FALSE}
# Ploteamos las palabras más frecuentes
token_sputnik_arg %>%
  count(word, sort = TRUE) %>%
  filter(n > 600 & n < 6000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = word)) +
  geom_col() +
  labs(y = "cantidad", title = "Cantidad de veces que se menciona cada palabra para tweets sobre SputnikV", subtitle = "Argentina") +
  xlab(NULL) +
  scale_fill_brewer(palette = "Spectral") +
  geom_text(aes( x=word, y=n, label=n), size=3) +
  coord_flip()


```

Al igual que Pfizer, la primera  palabra más utilizada es el nombre de la vacuna con 6551 observaciones y la palabra “vacuna” con 2882 observaciones. Ahora bien, lo que sí llama la atención, es que a diferencia de la Pfizer, aparecen dos países con una cantidad de menciones alta:  Rusia con 630 y Argentina 602 observaciones. Esta evidencia, muestra que la politización y polarización alrededor de la vacuna Sputnik V ocurre fuertemente.Incluso si uno observa la nube de palabras pugede encontrar que aparecen varios nombres de funcionarios de este país como “ginés”, “kicillof”, “vizzoti”.

Ahora graficamos las palabras utilizadas pero a traves de una nube de palabras.

#### Wordcloud

```{r echo=FALSE, message=FALSE, include=F}
# Word cloud

wordcloud_sp <- token_sputnik_arg %>%
  count(word, sort=T) %>%
  filter(n < 3000) %>% #eliminamos la palabra sputnik de la nube
  wordcloud2(size = 0.9, color = 'random-light', backgroundColor = "black")

wordcloud_sp

```

La nube de palabras nos muestra, al igual que el gráfico anterior, que la palabra más mencionada es "Vacuna".

```{r include=FALSE}
# Calculemos la cantidad de palabras por vacuna SputnikV
token_sp <- token_sputnik_arg %>%
  count(vacuna, word, sort = TRUE) %>%
  filter(n > 50)
#Calculamos la cantidad de palabras por la vacuna Pfizer
token_pf <- token_pfizer_arg %>%
  count(vacuna, word, sort = TRUE) %>%
  filter(n > 50)
# Uno los df
token_agrupado <- rbind(token_sp, token_pf)
total_palabras <- token_agrupado %>% 
  group_by(vacuna) %>% 
  summarize(total = sum(n))
token_agrupado <- left_join(token_agrupado, total_palabras)
```

### Sentiment Analisys 

Ahora realizemos un sentiment analisys para ver cuál es el sentimiento mayoritario entre las menciones de cada vacuna. 

```{r include=FALSE}
sentimientos <- read_tsv("https://raw.githubusercontent.com/7PartidasDigital/AnaText/master/datos/diccionarios/sentimientos_2.txt",col_types = "cccn", locale = default_locale())

sentimientos <- sentimientos %>% rename(word=palabra)

source("https://raw.githubusercontent.com/7PartidasDigital/R-LINHD-18/master/get_sentiments.R")

```

Para ello, cruzo con mi lexicón de sentimientos y empiezo a ver la distribución de sentimientos en los tweets. 
Probaremos en primer lugar con "NRC" y en segundo con "Bing"

```{r include=FALSE}
#Con NRC

token_agrupado %>%
  right_join(get_sentiments("nrc")) %>%
  filter(!is.na(sentimiento)) %>%
  count(sentimiento, sort = TRUE)

# Pruebo con bing para todo el corpus
token_agrupado %>%
  right_join(get_sentiments("bing")) %>%
  filter(!is.na(sentimiento)) %>%
  count(sentimiento, sort = TRUE)
```

Ahora ploteamos.

Primero ploteamos por NRC y luego por BING

```{r echo=FALSE}
# Ploteo por NRC 

token_agrupado %>%
  right_join(get_sentiments("nrc")) %>%
  na.omit() %>%
  filter(sentimiento != "negativo" & sentimiento !="positivo" & sentimiento != "disgusto") %>%
  count(vacuna, sentimiento, sort = TRUE) %>%
  ggplot(aes(sentimiento, n, fill = sentimiento)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_brewer(palette = "Paired") +
  theme_minimal() +
  facet_wrap(~vacuna, ncol = 2, scales = "free_x")+
  coord_flip()
```

En cuanto al análisis de sentimiento, partimos de la base que los n de palabras son diferentes para cada vacuna. Si bien no parece correcto hacer comparaciones entre ellas, si podemos hacer un analisis descriptivo de lo que vemos. 
Cuando se realiza el análisis de manera desagregada, el sentimiento de “confianza” es alto para ambas vacunas. 
Cabe destacar que para la vacuna Pfizer, los sentimientos más vistos además de la confianza, son miedo y premonición, al igual que la vacuna SputnikV. 

Sin embargo, a pesar de las conclusiones que uno puede sacar, hay que tener en cuenta que la dinamica misma de twitter hace que muchas veces lo que se dice sea en tono irónico. En este sentido, es importante el comentario ya que al propio algoritmo de análisis de sentimiento se le dificulta distinguir la irónia y puede "encasillar" tweets en determinado sentimiento cuando en realidad, si un humano lo lee, puede no lo "encasillaría" ahí.

Ahora ploteo por BING.

```{r echo=FALSE}
#Ploteo por bing

token_agrupado %>%
  right_join(get_sentiments("bing")) %>%
  na.omit() %>%
  count(vacuna, sentimiento, sort = TRUE) %>%
  arrange(vacuna, desc(n), sentimiento) %>% 
  ggplot(aes(vacuna, n, fill = sentimiento)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Pastel2") +
  theme_minimal() +
  facet_wrap(~vacuna, ncol = 2, scales = "free_x")

```

En cuanto al análisis agregado de los sentimientos, tanto positivos como negativos, vemos sorprendentemente que Pfizer obtiene más sentimientos negativos que positivos, mientras que la vacuna hecha en el país ruso  tiene una mejor relación entre ambos sentimientos, obteniendo un resultado de 50% para cada una. 

Estos últimos datos contrastan con el análisis desagregado de sentimientos. Al parecer, estos resultados seguramente requieren de un mejor procesamiento, ya que es probable que el banco de palabras que se utiliza para el análisis de sentimientos positivos y negativos, no esté del todo pulido y relacionado con el lenguaje que se usa en una plataforma tan informal y masiva como Twitter.

### Topic modeling

Por último, vamos a realizar un topic modeling para los tweets con ubicación en Argentina. La idea es clasificar los tweets en función de su temática. El objetivo es descubrir el tema subyacente, buscar patrones en el contenido de los tweets en base a la frecuencia de las palabras. 

Los pasos que sehguimos son:

1. Genero una matriz término-documento.

2. Aplico el topic modelling y utilizo la función ```LDA()``` (latent dirichlet allocation)

3. Paso el objeto a tidy.

4. Veo y ploteo los términos más frecuentes de mi topic modelling.

### Pfizer

```{r include=FALSE}
#Para realizar topic modeling primero debo generar una matriz término-documento, para ello utilizo la función  ```cast_dtm()```

data_conteo_pfizer <- token_pfizer_arg %>% count(status_id, word, sort=TRUE)

data_dtm_pfizer <- data_conteo_pfizer %>%
  cast_dtm(status_id, word, n)

data_dtm_pfizer $nrow
data_dtm_pfizer $ncol

```


```{r echo=FALSE}
#Ahora aplico mi topic modelling y utilizo la función ```LDA()``` (latent dirichlet allocation)

# Con k indico la cantidad de tópicos

data_lda_pfizer <- LDA(data_dtm_pfizer, k = 4, control = list(seed = 150))

# Paso el objeto a tidy, beta son las probabilidades per-topic-per-word

data_lda_td_pfizer <- tidy(data_lda_pfizer, matrix = "beta")

# Veo los términos más frecuentes de mi topic modelling
terminos_frecuentes_pfizer <- data_lda_td_pfizer %>%
  group_by(topic) %>%
  top_n(20, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Ploteo mis tópicos
terminos_frecuentes_pfizer %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  labs(title = "Tópicos") +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

### Sputnik

```{r include=FALSE}
data_conteo_sputnik <- token_sputnik_arg %>% count(status_id, word, sort=TRUE)

data_dtm_sputnik <- data_conteo_sputnik %>%
  cast_dtm(status_id, word, n)

data_dtm_sputnik $nrow
data_dtm_sputnik $ncol

```


```{r echo=FALSE}
# Con k indico la cantidad de tópicos

data_lda_sputnik <- LDA(data_dtm_sputnik, k = 4, control = list(seed = 150))

# Paso el objeto a tidy, beta son las probabilidades per-topic-per-word

data_lda_td_sputnik <- tidy(data_lda_sputnik, matrix = "beta")

# Veo los términos más frecuentes de mi topic modelling
terminos_frecuentes_sputnik <- data_lda_td_sputnik %>%
  group_by(topic) %>%
  top_n(20, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Ploteo mis tópicos
terminos_frecuentes_sputnik %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  labs(title = "Tópicos") +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```


### Conclusiones

Con el objetivo de cuantificar y descubrir qué se anda diciendo en twitter sobre las vacunas Pfizer y SputnikV, analizamos un corpus de tweets descargados durante los últimos 10 días de diciembre y los primeros 12 de enero. Luego de realizar una serie de analisis, concluimos que:

1. La cantidad de menciones que recibe cada vacuna por día depende directamente de la coyuntura y contexto del momento. Asi se observa en todos los países limítrofes en general y en Argentina en particular, donde los picos de menciones se corresponden a anuncios importantes del gobierno. 

2. Al analizar la dinámica de twitter observamos que hay grandes formadores de opiniones que a través de sus tweets tienen gran influencia en la comunidad y no son únicamente aquellos con cuenta verificada, sino también usuarios con varios seguidores o incluso usuarios con pocos seguidores pero con tweets que se volvieron virales. A partir de ello quisimos realizar un analisis de redes que nos explique un poco más como se difunden los mensajes y qué comunidades se forman. 

3. Al analizar las palabras más frecuentes en los tweets, observamos en ambos casos que hay una gran politización y polarización del tema. En algunos casos más notada, por ejemplo en las menciones de Pfizer  donde además se menciona en gran medida vacunas desarrolladas por otros laboratorios. Creemos que este hallazgo nos da puntapie para en un futuro analizar la postura partidaría de los mayores formadores de opinión sobre nuestra muestra. 

4. Por último, al analizar los sentimientos que se desprenden de los tweets nos encontramos con varias trabas. Creemos que el análisis de sentimiento no se aplica del todo a la dinámica de twitter (lenguaje que se usa en una plataforma tan informal y masiva como Twitter) o quizás los datos requieran de un mejor procesamiento.


Para finalizar, si bien no encontramos hallazgos muy interesantes como nos imaginabamos, si creemos que fué relevante el tema de análisis. En primer lugar, porque sirvió para cuantificar cuánto se habla del tema en una red social como lo es twitter. En segundo, porque es un tema actual y el momento en el que descargamos los tweets coincidió con grandes anuncios tanto en Argentina como en el resto del mundo.